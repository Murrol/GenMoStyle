<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Generative Human Motion Stylization in Latent Space</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Generative Human Motion Stylization in Latent Space</h1>
          <div class="is-size-3 publication-authors">
            ICLR 2024
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://ericguo5513.github.io/">Chuan Guo</a><sup>1*</sup>,</span>
            <span class="author-block">
              <a href="https://yxmu.foo/">Yuxuan Mu</a><sup>1*</sup>,</span>
            <span class="author-block">
              <a href="https://sites.google.com/site/xinxinzuohome/home">Xinxin Zuo</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://pdaicode.github.io/index.html">Peng Dai</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=JPUwfAMAAAAJ&hl=zh-CN">Youliang Yan</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.ca/citations?user=Asz24wcAAAAJ&hl=en">Juwei Lu</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.ece.ualberta.ca/~lcheng5/">Li Cheng</a><sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>University of Alberta</span>&nbsp
            <span class="author-block"><sup>2</sup>Noah's Ark Lab, Huawei Canada</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://openreview.net/pdf?id=daEqXJ0yZo"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a 
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <!-- <span class="link-block">
                <a href="https://huggingface.co/spaces/MeYourHint/MoMask" target="_blank"
                class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                  <i class="fas fa-rocket"></i>
                </span>
                <span>Demo (Coming soon)</span>
                </a> -->
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    
        <!-- <center><h2 class="title is-3">Abstract</h2></center> -->
    <div class="hero-body has-text-centered">
        <img src = "./static/images/teaser.png" height="80%"></img><br>

    </div>

    <p style="text-align: justify; margin-inline: 5% 5%;"> 
      Human motion stylization aims to revise the style of an input motion while keeping its content unaltered. Unlike existing works that operate directly in pose space, we leverage the <i>latent space</i> of pretrained autoencoders as a more expressive and robust representation for motion extraction and infusion. Building upon this, we present a novel <i>generative</i> model that produces diverse stylization results of a single motion (latent) code. During training, a motion code is decomposed into two coding components: a deterministic content code, and a probabilistic style code adhering to a prior distribution; then a generator massages the random combination of content and style codes to reconstruct the corresponding motion codes. Our approach is versatile, allowing the learning of probabilistic style space from either style labeled or unlabeled motions, providing notable flexibility in stylization as well. In inference, users can opt to stylize a motion using style cues from a reference motion or a label. Even in the absence of explicit style input, our model facilitates novel re-stylization by sampling from the unconditional style prior distribution. Experimental results show that our proposed stylization models, despite their lightweight design, outperform the state-of-the-arts in style reeanactment, content preservation, and generalization across various applications and settings.
    </p>
    <br>
    <!-- <div class="content has-text-centered">
      <video id="replay-video"
            autoplay 
             controls
             playsinline
             width="80%">
        <source src="./static/video/demo.mp4"
                type="video/mp4">
      </video>
    </div> -->
    <!-- <div id="video-container">
      <video id="video" muted controls playsinline>
        <source src="./static/video/demo.mp4" type="video/mp4">
      </video>
      <span style="font-size:12px">* This video contains audio.</span>
    </div> -->
    
  </div>
</section>



<section class="section is-light is-small">
  <div class="container is-max-desktop">
    <center><h2 class="title is-3">Approach Overview</h2></center>
    <div class="hero-body">
      <a href="./static/images/model.png"><img src = "./static/images/model.png" height="100%"></img></href></a><br>
    </div>
  </div>
    <!--/ Abstract. -->

</section>


<section class="hero is-small is-light">
  <center><h2 class="title is-3">Label-based Stylization Gallery </h2></center>
  <div class="hero-body">
    <p style="text-align: center;">Left: <b>Content</b> motions &nbsp Right: <b>Stylized</b> motoins</p>
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="column is-centered has-text-centered">
          <p><b> Style: Zombie </b></p><br>
          <video poster="" id="tree" autoplay controls muted loop playsinline height="100%">
            <source src="./static/video/gallery/CMU_11_Zombie_0001-0160.mp4#t=0.01" type="video/mp4">
          </video>
        </div>
        <div class="column is-centered has-text-centered">
          <p><b> Style: Sneaky </b></p><br>
          <video poster="" id="tree" autoplay controls muted loop playsinline height="100%">
            <source src="./static/video/gallery/CMU_13_Sneaky_0001-0160.mp4#t=0.01" type="video/mp4">
          </video>
        </div>
        <div class="column is-centered has-text-centered">
          <p><b> Style: FemaleModel </b></p><br>
          <video poster="" id="tree" autoplay controls muted loop playsinline height="100%">
            <source src="./static/video/gallery/Proud_Fem_06_0001-0160.mp4#t=0.01" type="video/mp4">
          </video>
        </div>
        <div class="column is-centered has-text-centered">
          <p><b> Style: Old </b></p><br>
          <video poster="" id="tree" autoplay controls muted loop playsinline height="100%">
            <source src="./static/video/gallery/Heavy_Old_05_0001-0160.mp4#t=0.01" type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">

    <center><h2 class="title is-3">Label-based Stylization (Diverse)</h2></center><br>
    <div class="content has-text-centered">
      <video id="replay-video"
             controls
             muted
             preload
             playsinline
             width="80%">
        <source src="./static/video/diverse.mp4#t=0.01"
                type="video/mp4">
      </video>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">

    <center><h2 class="title is-3">Motion-based Stylization</h2></center><br>
    <div class="content has-text-centered">
      <video id="replay-video"
             controls
             muted
             preload
             playsinline
             width="80%">
        <source src="./static/video/3_motion_based_stylization.mp4#t=0.01"
                type="video/mp4">
      </video>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <center><h2 class="title is-3">Prior-based Stylization</h2></center><br>
    <p>
      Styles are sampled from our probabilistic style space.
    </p>
    <br>
    <div class="content has-text-centered">
      <video id="replay-video"
             controls
             muted
             preload
             playsinline
             width="80%">
        <source src="./static/video/4_prior_based_stylization.mp4#t=0.01"
                type="video/mp4">
      </video>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <center><h2 class="title is-3">Probabilistic Style Space</h2></center><br>
    <div class="content has-text-justified">
      <p>
        We highlight the features of our probabilistic style space by showcasing its <b>diverse</b> stylization capacity and style <b>interpolation</b> ability. <br>
      </p>
      <br>
      <div class="content has-text-centered">
        <video id="replay-video"
                controls
                muted
                preload
                playsinline
                width="80%">
          <source src="./static/video/5_interpolation.mp4#t=0.01"
                  type="video/mp4">
        </video>
      </div>
    </div>
  </div>
  
</section>

<section class="section">
  <div class="container is-max-desktop">

    <center><h2 class="title is-3">Application: Text2Motion Stylization</h2></center><br>
    <p>
      We showcase the generalization ability of our method to stylize the OOD motions generated from an off-the-shelf <a href="https://huggingface.co/spaces/MeYourHint/MoMask">T2M model</a>. 
    </p>
    <div class="content has-text-centered">
      <video id="replay-video"
             controls
             muted
             preload
             playsinline
             width="80%">
        <source src="./static/video/1_stylized_text2motion.mp4#t=0.01"
                type="video/mp4">
      </video>
    </div>
  </div>
</section>

<!-- <section class="section">
  <div class="container is-max-desktop">
    <center><h2 class="title is-3">Comparisons</h2></center><br>
    <div class="content has-text-justified">
      <p>
        We compare our proposal against three strong baseline approaches in motion-based and label-based settings. In contrast to these prior works, our works generate more realistic motions with more expressive style. <br>
      </p>
      <div class="content has-text-centered">
        <video id="replay-video"
               controls
               muted
               preload
               playsinline
               width="100%">
          <source src="./static/video/comparison.mp4#t=0.01"
                  type="video/mp4">
        </video>
      </div>
    </div>
  </div>
  
</section> -->


<section class="section is-light">
  <div class="container is-max-desktop">
    <center><h2 class="title is-3">Content Motion Generation Works &#128640&#128640</h2></center><br>
    <div class="content has-text-justified">
    <a href="https://ericguo5513.github.io/momask/"><b>MoMask</b></a>: Swift text-driven motion generation through mask generative modeling.<br>
    <a href="https://ericguo5513.github.io/TM2D/"><b>TM2D</b></a>: Learning dance generation with textual instruction.<br>
    <a href="https://ericguo5513.github.io/action-to-motion//"><b>Action2Motion</b></a>: Diverse action-conditioned motion generation.<br>
  </div>
  
</section>




<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@inproceedings{
      guo2024generative,
      title={Generative Human Motion Stylization in Latent Space},
      author={Chuan Guo, Yuxuan Mu, Xinxin Zuo, Peng Dai, Youliang Yan, Juwei Lu, Li Cheng},
      booktitle={The Twelfth International Conference on Learning Representations},
      year={2024},
      url={https://openreview.net/forum?id=daEqXJ0yZo}
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="columns is-centered">
    <div class="column is-8">
      <div class="content">
        <p><sup><b>*</b></sup> These authors contributed to this work equally.</p>
        <p>
          This website is licensed under a <a rel="license"
          href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
        Commons Attribution-ShareAlike 4.0 International License</a>.
      </p>
      <p>
        Website source code based on the <a href="https://nerfies.github.io/"> Nerfies</a> project page. If you want to reuse their <a
        href="https://github.com/nerfies/nerfies.github.io">source code</a>, please credit them appropriately.
      </p>
    </div>
  </div>
</div>
</div>
</footer>

<script>
      var videoContainer = document.getElementById('video-container');
      var video = document.getElementById('video');

      var videoOffset = videoContainer.offsetTop;

      window.addEventListener('scroll', function() {
        var scrollPosition = window.scrollY || window.pageYOffset;

        if (scrollPosition >= videoOffset) {
          video.play();
        } else {
          video.pause();
        }
      });
    </script>

</body>
</html>
